{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fish Species lite basic",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Fish species classification. Basic model (test)"
      ],
      "metadata": {
        "id": "Na4lIX23ZuHQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irE8E7pX5W2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2ba57b-c1fc-4108-e380-868a13be4d76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdWf-SZ-kbrE"
      },
      "source": [
        "###Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6LVQ5OXkwh4"
      },
      "source": [
        "###Converting Images to MobileNet Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKnABi7HCI9y"
      },
      "source": [
        "Image_Size=56 #4:3\n",
        "(img_height, img_width)=(224,224)#(Image_Size*3,Image_Size*4)#4:3\n",
        "\n",
        "def set_ratio(img):\n",
        "  desired_ratio = (img_height ) /(img_width)\n",
        "  initial_ratio = img.shape[0] / img.shape[1]\n",
        "\n",
        "  if initial_ratio > desired_ratio:\n",
        "    img=np.pad(img,((0,0),(0, round(img.shape[1] *(initial_ratio/ desired_ratio -1. ))),(0,0)),mode='mean')\n",
        "  else:\n",
        "    img=np.pad(img,((0, round(img.shape[0] * (desired_ratio / initial_ratio -1.))) ,(0,0),(0,0)),mode='mean')\n",
        "  return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns9hbEoclI89"
      },
      "source": [
        "####Setting the catalog - the source of images and the generator that converts images into feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4s8HckqGlnb"
      },
      "source": [
        "# Define our example directories and files\n",
        "\n",
        "train_data_dir='/content/drive/MyDrive/myFish'\n",
        "batch_size=120\n",
        "nb_epochs=15\n",
        "\n",
        "datagen =  tf.keras.preprocessing.image.ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range = 40,\n",
        "    zoom_range = 0.5,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function = set_ratio,\n",
        "    validation_split=0.1) \n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode= 'categorical',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data\n",
        "\n",
        "\n",
        "classnum = len(train_generator.class_indices)# number of presented categories\n",
        "\n",
        "pre_trained_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
        "                                                           input_shape=(img_height, img_width,3),weights='imagenet')\n",
        "pre_trained_model.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G0RGR6ouUhJ"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmsvkE_ji6Dt"
      },
      "source": [
        "last_layer=pre_trained_model.layers[-2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "374WHcn3PUA8"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "print('last layer output shape: ', last_layer.output_shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKHDKiQSvDwO"
      },
      "source": [
        "#Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,Adamax\n",
        "x = layers.Flatten()(last_layer.output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a final softmax layer for classification by as many classes as folders of pictures you have\n",
        "x = layers.Dense(classnum, activation='softmax')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = Adamax(lr=0.001),\n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmeKY7yHNd4v"
      },
      "source": [
        "### Directory for saving model scales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcHKK4_sNPmv"
      },
      "source": [
        "weight_saving = '/content/drive/MyDrive/fish/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6fbIN9PAyEp"
      },
      "source": [
        "init_lr =1e-4\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "      lambda epoch: init_lr * 10**(epoch / 10))\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callback_stopbyneat = myCallback()\n",
        "\n",
        "callback_tuneLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=5, min_lr=1e-7, min_delta=0.001, factor=0.5)\n",
        "callback_saveweights = tf.keras.callbacks.ModelCheckpoint(filepath=weight_saving+'model3fish.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "                                                          monitor='val_loss', save_best_only=True,\n",
        "                                                          save_weights_only=True\n",
        "                                                          ),\n",
        "callback_tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNejBq0YpTQ6"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/fish/model3fish.12-0.36.h5',skip_mismatch=True, by_name =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq2MAUeyGA"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples // batch_size,\n",
        "    validation_data = validation_generator, \n",
        "    validation_steps = validation_generator.samples // batch_size,\n",
        "    epochs=20,\n",
        "    callbacks=[callback_saveweights, callback_tensorboard, callback_tuneLR]\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK-B9JOgOjbt"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Wzq9FHX-EK"
      },
      "source": [
        "#Checking the first results with real pictures\n",
        "\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqbQju55jK7Z"
      },
      "source": [
        "import scipy.ndimage as sc\n",
        "\n",
        "vectors=[]\n",
        "num=len(uploaded)\n",
        "fig = plt.figure(figsize=[3,3*num])\n",
        "i=0\n",
        "axes=[]\n",
        "for fn in uploaded.keys():\n",
        "        # Predicting images\n",
        "        path = '/content/' + fn\n",
        "        img = image.load_img(path)\n",
        "        x = image.img_to_array(img)\n",
        "        x= set_ratio(x)\n",
        "        # print(x.shape)\n",
        "        im = np.stack(( sc.zoom(x[:,:,s],img_height/x.shape[0]) for s in range(x.shape[2])),axis=2)\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        vectors.append(im)\n",
        "        i+=1\n",
        "        ax = fig.add_subplot(num,1, i) \n",
        "        axes.append(ax)\n",
        "        ax.imshow(img)\n",
        "        # print(im.shape)\n",
        "\n",
        "vectors = np.vstack(vectors)\n",
        "classes = model.predict(vectors/255., batch_size=batch_size)\n",
        "fish = train_generator.class_indices\n",
        "\n",
        "answers = np.array(list(fish.keys()))[classes.argmax(axis=1)]\n",
        "for i in range(num):\n",
        "  axes[i].set_title(answers[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgqRCej6gZI7"
      },
      "source": [
        "fish.keys()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ILokX_DicG",
        "outputId": "0a48c382-ba36-446d-a667-d4c4e232530a"
      },
      "source": [
        "img_height/x.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7225806451612903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKPyJXf_5DZ6",
        "outputId": "8207c497-6b95-40de-8b37-0ddb7d0bdf54"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9534407 , 0.04655926],\n",
              "       [0.9908296 , 0.00917044],\n",
              "       [0.9915597 , 0.00844033],\n",
              "       [0.98656   , 0.01344001],\n",
              "       [0.76847255, 0.23152742],\n",
              "       [0.25649363, 0.7435063 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}